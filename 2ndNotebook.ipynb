{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_train.csv\", low_memory = False)\n",
    "df['Respondent Address (Zip Code)'] = df['Respondent Address (Zip Code)'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to fill in UNKNOWN for all NAs in the dataframe\n",
    "def fill_na(column):\n",
    "    \n",
    "    for x in column:\n",
    "        df[x].fillna('UNKNOWN', inplace=True)\n",
    "    \n",
    "    return df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(df.columns)\n",
    "fill_na(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see that is the case\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Charge #2: Infraction Amount\"].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in neighborhood level income data from the census \n",
    "\n",
    "1. main problem is USPS zip code (which is what the main df has) is different from census's zip code tabulation area number (thought a signficant portion of them match up identically). For example, one's USPS zip code could be 11333 but its zip code tabulation area could be 11332\n",
    "\n",
    "2. Need to go through the following steps to get the census data to match up with the main dataframe \n",
    "\n",
    "     A. add a new column with ZIP Code Tabulation Areas (ZCTAs) so to pull census data using ZCTA\n",
    "     \n",
    "     B. web scrape census to get the list of ZCTA based on the dataframe \n",
    "     \n",
    "     C. merge the dataframes together so each row contain neighborhood level income data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_zip_codes = [\"10001\", \"10002\", \"10003\", \"10004\", \"10005\", \"10006\",\n",
    "                 \"10007\",\"10009\",\"10010\",\"10011\",\"10012\",\"10013\",\"10014\",\n",
    "                 \"10015\",\"10016\",\"10017\",\"10018\",\"10019\",\"10020\",\"10021\",\n",
    "                 \"10022\",\"10023\",\"10024\",\"10025\",\"10026\",\"10027\",\"10028\",\n",
    "                 \"10029\",\"10030\",\"10031\",\"10032\",\"10033\",\"10034\",\"10035\",\n",
    "                 \"10036\",\"10037\",\"10038\",\"10039\",\"10040\",\"10041\",\"10044\",\n",
    "                 \"10045\",\"10048\",\"10055\",\"10060\",\"10069\",\"10090\",\"10095\",\n",
    "                 \"10098\",\"10099\",\"10103\",\"10104\",\"10105\",\"10106\",\"10107\",\n",
    "                 \"10110\",\"10111\",\"10112\",\"10115\",\"10118\",\"10119\",\"10120\",\n",
    "                 \"10121\",\"10122\",\"10123\",\"10128\",\"10151\",\"10152\",\"10153\",\n",
    "                 \"10154\",\"10155\",\"10158\",\"10161\",\"10162\",\"10165\",\"10166\",\n",
    "                 \"10167\",\"10168\",\"10169\",\"10170\",\"10171\",\"10172\",\"10173\",\n",
    "                 \"10174\",\"10175\",\"10176\",\"10177\",\"10178\",\"10199\",\"10270\",\n",
    "                 \"10271\",\"10278\",\"10279\",\"10280\",\"10281\",\"10282\",\"10301\",\n",
    "                 \"10302\",\"10303\",\"10304\",\"10305\",\"10306\",\"10307\",\"10308\",\n",
    "                 \"10309\",\"10310\",\"10311\",\"10312\",\"10314\",\"10451\",\"10452\",\n",
    "                 \"10453\",\"10454\",\"10455\",\"10456\",\"10457\",\"10458\",\"10459\",\n",
    "                 \"10460\",\"10461\",\"10462\",\"10463\",\"10464\",\"10465\",\"10466\",\n",
    "                 \"10467\",\"10468\",\"10469\",\"10470\",\"10471\",\"10472\",\"10473\",\n",
    "                 \"10474\",\"10475\",\"11004\",\"11101\",\"11102\",\"11103\",\"11104\",\n",
    "                 \"11105\",\"11106\",\"11109\",\"11201\",\"11203\",\"11204\",\"11205\",\n",
    "                 \"11206\",\"11207\",\"11208\",\"11209\",\"11210\",\"11211\",\"11212\",\n",
    "                 \"11213\",\"11214\",\"11215\",\"11216\",\"11217\",\"11218\",\"11219\",\n",
    "                 \"11220\",\"11221\",\"11222\",\"11223\",\"11224\",\"11225\",\"11226\",\n",
    "                 \"11228\",\"11229\",\"11230\",\"11231\",\"11232\",\"11233\",\"11234\",\n",
    "                 \"11235\",\"11236\",\"11237\",\"11238\",\"11239\",\"11241\",\"11242\",\n",
    "                 \"11243\",\"11249\",\"11252\",\"11256\",\"11351\",\"11354\",\"11355\",\n",
    "                 \"11356\",\"11357\",\"11358\",\"11359\",\"11360\",\"11361\",\"11362\",\n",
    "                 \"11363\",\"11364\",\"11365\",\"11366\",\"11367\",\"11368\",\"11369\",\n",
    "                 \"11370\",\"11371\",\"11372\",\"11373\",\"11374\",\"11375\",\"11377\",\n",
    "                 \"11378\",\"11379\",\"11385\",\"11411\",\"11412\",\"11413\",\"11414\",\n",
    "                 \"11415\",\"11416\",\"11417\",\"11418\",\"11419\",\"11420\",\"11421\",\n",
    "                 \"11422\",\"11423\",\"11426\",\"11427\",\"11428\",\"11429\",\"11430\",\n",
    "                 \"11432\",\"11433\",\"11434\",\"11435\",\"11436\",\"11691\",\"11692\",\n",
    "                 \"11693\",\"11694\",\"11697\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset contains USPS zip_code and ZCTA zip code for several states. \n",
    "# itindicates whether some a USPS zip code matches with a ZCTA code\n",
    "# if certain ones doesn't match up, it indicates the equivalence of that\n",
    "\n",
    "\n",
    "ZiptoZcta_Crosswalk_2021 = pd.read_excel(\"ZiptoZcta_Crosswalk_2021.xlsx\")\n",
    "ZiptoZcta_Crosswalk_2021[\"ZIP_CODE\"] = ZiptoZcta_Crosswalk_2021[\"ZIP_CODE\"].astype(str)\n",
    "df['Respondent Address (Zip Code)'] = df['Respondent Address (Zip Code)'].astype(str)\n",
    "\n",
    "# narrown down the df to only pull out zip codes that matches the nyc zipcode list above\n",
    "ZiptoZcta_Crosswalk_2021[\"ZIP_CODE_NYC\"] = np.where(ZiptoZcta_Crosswalk_2021[\"ZIP_CODE\"].isin(nyc_zip_codes), \"NYC\", \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ZiptoZcta_Crosswalk_2021[\"ZIP_CODE_NYC\"].value_counts())\n",
    "\n",
    "ZiptoZcta_Crosswalk_2021_NYC = ZiptoZcta_Crosswalk_2021.loc[ZiptoZcta_Crosswalk_2021[\"ZIP_CODE_NYC\"] == \"NYC\"]\n",
    "ZiptoZcta_Crosswalk_2021_NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZiptoZcta_Crosswalk_2021_NYC.to_csv(\"NYC_Only_ZiptoZcta_Crosswalk_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dic that has the usps zip code on the left and ZCTA code on the right so we can map it \n",
    "ZiptoZcta_Crosswalk_2021_NYC_dict = dict(zip(ZiptoZcta_Crosswalk_2021_NYC.ZIP_CODE, ZiptoZcta_Crosswalk_2021_NYC.ZCTA))\n",
    "ZiptoZcta_Crosswalk_2021_NYC_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the key above, if the respondent address column matches the key, then the new column will match it with the value\n",
    "df['Respondent ZCTA'] = df['Respondent Address (Zip Code)'].map(ZiptoZcta_Crosswalk_2021_NYC_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Respondent ZCTA\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Respondent ZCTA'] = df[\"Respondent ZCTA\"].astype(str)\n",
    "\n",
    "print(\"Respondent ZCTA column contains a total {} unique zip codes. I will use this list to do web scraping\\\n",
    "to get the relevant census files\".format(len(df['Respondent ZCTA'].unique())))\n",
    "\n",
    "Respondent_ZCTA_list = list(set(df['Respondent ZCTA']))\n",
    "print(Respondent_ZCTA_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromedriver-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_binary\n",
    "#import get to call a get request on the site\n",
    "from requests import get\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import chromedriver_binary\n",
    "\n",
    "driver = webdriver.Chrome(\"/Users/allisongao/Downloads/chromedriver 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZCTA_url =[]\n",
    "\n",
    "for x in Respondent_ZCTA_list:\n",
    "    ZCTA_url.append(\"https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US\" + x + \"&tid=ACSST5Y2019.S1901&hidePreview=true\")\n",
    "    \n",
    "    \n",
    "ZCTA_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to auto click on the download button to get all the census data\n",
    "import time\n",
    "# #importing webdriver from selenium\n",
    "# from selenium import webdriver\n",
    " \n",
    "# # Here Chrome  will be used\n",
    "# driver = webdriver.Chrome(\"/Users/allisongao/Downloads/chromedriver 4\")\n",
    " \n",
    "# firs_group = ['https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11229&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11215&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11435&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11208&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11367&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US11206&tid=ACSST5Y2019.S1901&hidePreview=true',\n",
    "#  'https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US10458&tid=ACSST5Y2019.S1901&hidePreview=true']\n",
    "    \n",
    "# # URL of website\n",
    "\n",
    "# for url in firs_group:\n",
    "#     driver.get(url)\n",
    "    \n",
    "#     downloadBtn = driver.find_element_by_xpath(\"//*[text() = 'Download']\")\n",
    "#     downloadBtn.click()\n",
    "#     time.sleep(5)\n",
    "#     downloadBtn2 = driver.find_element_by_xpath(\"//button[@class='aqua-button mt-5']\")\n",
    "#     downloadBtn2.click()\n",
    "#     time.sleep(2)\n",
    "#     downloadBtn3=driver.find_element_by_xpath('//*[@id=\"table-download-now-button\"]')\n",
    "#     downloadBtn3.click()\n",
    "\n",
    "\n",
    "for x in Respondent_ZCTA_list_39:\n",
    "    \n",
    "    link=\"https://data.census.gov/cedsci/table?q=mean%20income&g=8600000US\" + x + \"&tid=ACSST5Y2019.S1901&hidePreview=true\"\n",
    "#     link= x\n",
    "    driver.get(link)\n",
    "    downloadBtn = driver.find_element_by_xpath(\"//*[text() = 'Download']\")\n",
    "    downloadBtn.click()\n",
    "    time.sleep(60)\n",
    "    downloadBtn2 = driver.find_element_by_xpath(\"//button[@class='aqua-button mt-5']\")\n",
    "    downloadBtn2.click()\n",
    "    time.sleep(60)\n",
    "    downloadBtn3=driver.find_element_by_xpath('//*[@id=\"table-download-now-button\"]')\n",
    "    downloadBtn3.click()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the census data by zip code and concat it into a single dataframe\n",
    "\n",
    "zcta_df = []\n",
    "\n",
    "for x in range(1, 190):\n",
    "    data = pd.read_csv(str(x) + \"ACS.csv\")\n",
    "    \n",
    "    zcta_df.append(data)\n",
    "    \n",
    "#merge them all horizontally \n",
    "zcta_df = pd.concat(zcta_df)   \n",
    "\n",
    "\n",
    "#drop duplicated rows\n",
    "zcta_df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "zcta_df = zcta_df.reset_index(drop=True)\n",
    "\n",
    "#second row is an observation for the entire country, let's drop it\n",
    "zcta_df.drop(2, inplace=True)\n",
    "\n",
    " #change the first row for the header\n",
    "new_header = zcta_df.iloc[0]\n",
    "zcta_df = zcta_df[1:]\n",
    "zcta_df.columns = new_header \n",
    "\n",
    "#make sure df is in good shape\n",
    "zcta_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert the Geographic Area Name column so that I can use this to merge it to the main df\n",
    "zcta_df[\"Geographic Area Name\"]= zcta_df[\"Geographic Area Name\"].str.replace('ZCTA5', '')\n",
    "zcta_df['Geographic Area Name'] = zcta_df['Geographic Area Name'].astype(str)\n",
    "zcta_df['Geographic Area Name'] = zcta_df['Geographic Area Name'].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list (zcta_df.columns.tolist()):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the census data df has a lot of information\n",
    "# isolate the relevant columns for the final df\n",
    "\n",
    "columns = ['Geographic Area Name',\n",
    "           \n",
    "            \"Estimate!!Nonfamily households!!Median income (dollars)\",\n",
    "            \"Estimate!!Nonfamily households!!Mean income (dollars)\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!Less than $10,000\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$10,000 to $14,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$15,000 to $24,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$25,000 to $34,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$35,000 to $49,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$50,000 to $74,999\",\n",
    "           \n",
    "           \n",
    "           \n",
    "           \"Estimate!!Households!!Median income (dollars)\",\n",
    "           \"Estimate!!Households!!Mean income (dollars)\",\n",
    "           \"Estimate!!Households!!Total!!Less than $10,000\",\n",
    "            \"Estimate!!Households!!Total!!$10,000 to $14,999\",\n",
    "            \"Estimate!!Households!!Total!!$15,000 to $24,999\",\n",
    "            \"Estimate!!Households!!Total!!$25,000 to $34,999\",\n",
    "            \"Estimate!!Households!!Total!!$35,000 to $49,999\",\n",
    "            \"Estimate!!Households!!Total!!$50,000 to $74,999\"]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_df = zcta_df[columns]\n",
    "zcta_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_df = zcta_df.rename(columns={\"Geographic Area Name\": 'Respondent Address (Zip Code)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[7550,17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge main df with the census df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df = pd.merge(df, zcta_df, how=\"outer\", on=[\"Respondent Address (Zip Code)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.drop(merged_train_df.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moved the target column to the first for easier visual\n",
    "first_column = merged_train_df.pop('Hearing Result')\n",
    "merged_train_df.insert(0, 'Hearing Result', first_column)\n",
    "merged_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Hearing Result\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_fill_na = [\n",
    "            \"Estimate!!Nonfamily households!!Median income (dollars)\",\n",
    "            \"Estimate!!Nonfamily households!!Mean income (dollars)\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!Less than $10,000\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$10,000 to $14,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$15,000 to $24,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$25,000 to $34,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$35,000 to $49,999\",\n",
    "            \"Estimate!!Nonfamily households!!Total!!$50,000 to $74,999\",\n",
    "           \"Estimate!!Households!!Median income (dollars)\",\n",
    "           \"Estimate!!Households!!Mean income (dollars)\",\n",
    "           \"Estimate!!Households!!Total!!Less than $10,000\",\n",
    "            \"Estimate!!Households!!Total!!$10,000 to $14,999\",\n",
    "            \"Estimate!!Households!!Total!!$15,000 to $24,999\",\n",
    "            \"Estimate!!Households!!Total!!$25,000 to $34,999\",\n",
    "            \"Estimate!!Households!!Total!!$35,000 to $49,999\",\n",
    "            \"Estimate!!Households!!Total!!$50,000 to $74,999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(column):\n",
    "    \n",
    "    for x in column:\n",
    "        merged_train_df[x].fillna('UNKNOWN', inplace=True)\n",
    "    \n",
    "    return merged_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_na(columns_fill_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Violation Location (Borough)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looked through each of the unknown category and corrected their borough based on the addressed provided \n",
    "list_zip_code_change_MA = [5149, 56147,113291,149645,187366, 95107,194000,211902]\n",
    "\n",
    "for x in list_zip_code_change_MA:\n",
    "    merged_train_df.at[x, \"Violation Location (Borough)\"] = \"MANHATTAN\"\n",
    "    \n",
    "    \n",
    "\n",
    "list_zip_code_change_QNS = [52891, 100964,183982,201329]\n",
    "\n",
    "for x in list_zip_code_change_QNS:\n",
    "    merged_train_df.at[x, \"Violation Location (Borough)\"] = \"QUEENS\"\n",
    "    \n",
    "    \n",
    "    \n",
    "list_zip_code_change_SI = [59790, 72781,60756,7278,73248,73613,206307]\n",
    "\n",
    "for x in list_zip_code_change_SI:\n",
    "    merged_train_df.at[x, \"Violation Location (Borough)\"] = \"STATEN IS\"\n",
    "    \n",
    "    \n",
    "merged_train_df.at[48408, \"Violation Location (Zip Code)\"] = 10038\n",
    "merged_train_df.at[210827, \"Violation Location (Zip Code)\"] = 11559\n",
    "merged_train_df.at[210873, \"Violation Location (Zip Code)\"] = 11692\n",
    "merged_train_df.at[210879, \"Violation Location (Zip Code)\"] = 11233\n",
    "merged_train_df.at[210892, \"Violation Location (Zip Code)\"] = 11692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure this column is corrected\n",
    "merged_train_df[\"Violation Location (Borough)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Violation Location (Zip Code)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Respondent Address (Zip Code)\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling out weird respondent address zip code \n",
    "\n",
    "117792218 = 11779\n",
    "\n",
    "117571211 = 11757\n",
    "117433914 \n",
    "112212517\n",
    "117576451\n",
    "117983702\n",
    "117274069       \n",
    "105471054       \n",
    "7055 =07055 NJ\n",
    "7102 ==07102 NJ\n",
    "107012849\n",
    "8879 == 08879NJ\n",
    "1008 == unclear delete unknown \n",
    "115424211 \n",
    "104576724\n",
    "101\n",
    "7506\n",
    "117573534       \n",
    "117033221       \n",
    "107             \n",
    "116913065       \n",
    "100103202\n",
    "115544540\n",
    "8610\n",
    "115201726 \n",
    "2908\n",
    "103010468 \n",
    "112170022\n",
    "7083\n",
    "116931854\n",
    "1226\n",
    "113733607\n",
    "7166\n",
    "7050\n",
    "7036\n",
    "116914809\n",
    "103\n",
    "7011\n",
    "7112\n",
    "7043\n",
    "117691823       \n",
    "107103211       \n",
    "117530754       \n",
    "115503908\n",
    "1915\n",
    "109181420\n",
    "110035033\n",
    "8701\n",
    "115503445\n",
    "7047\n",
    "7073 \n",
    "112041721 \n",
    "116920311  \n",
    "116900171     \n",
    "117794358 \n",
    "7014\n",
    "116972206\n",
    "110\n",
    "113551701 \n",
    "112324228\n",
    "115581926       \n",
    "7065\n",
    "115504822\n",
    "116941710\n",
    "112\n",
    "7054 \n",
    "111\n",
    "7033 \n",
    "752\n",
    "100290289       \n",
    "112321637       \n",
    "125949759       \n",
    "112171006 \n",
    "112022783 \n",
    "117061409\n",
    "100\n",
    "196\n",
    "7307\n",
    "7303\n",
    "1105\n",
    "7105\n",
    "116931498\n",
    "7631\n",
    "113\n",
    "7032            \n",
    "7726\n",
    "116915609 \n",
    "100302472\n",
    "115012242\n",
    "112181121\n",
    "107042262\n",
    "115532021\n",
    "116932127\n",
    "105531607\n",
    "115504718  \n",
    "116972203\n",
    "7304\n",
    "1120\n",
    "112181852 \n",
    "11\n",
    "117252116\n",
    "104 \n",
    "7306\n",
    "110961359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Decision Location (Borough)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the value counts above, we can group this column to make it cleaner\n",
    "\n",
    "\n",
    "merged_train_df['Decision Location (Borough)'] = merged_train_df['Decision Location (Borough)'].map(\n",
    "                                     {'UNKNOWN': \"UNKNOWN\",\n",
    "                                      'MANHATTAN': 'In Person MANHATTAN',\n",
    "                                      'BROOKLYN': \"In Person BROOKLYN\",\n",
    "                                      'QUEENS': \"In Person QUEENS\",\n",
    "                                      'BRONX': \"In Person BRONX\",\n",
    "                                      'SAU: MANH': \"By Mail MANHATTAN\",\n",
    "                                      'BY PHONE': \"BY PHONE\",\n",
    "                                      'STATEN IS': \"STATEN IS\",\n",
    "                                     'LONG ISLA': \"In Person QUEENS\",\n",
    "                                     'SAU: BX': \"By Mail BRONX\",\n",
    "                                     'SAU: BKLN': \"By Mail BKLN\",\n",
    "                                     'SAU: LIC': \"By Mail QUEENS\",\n",
    "                                     'ONE-CLICK ': \"Electronic\"\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Decision Location (Borough)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[merged_train_df[\"Penalty Imposed\"] != \"UNKNOWN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Paid Amount\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Penalty Imposed\"].astype(int)\n",
    "merged_train_df[\"Paid Amount\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Penalty Imposed - Paid Amount\"] = merged_train_df[\"Penalty Imposed\"] - merged_train_df[\"Paid Amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Charge #1: Code                                            213243 non-null  object \n",
    "Charge #1: Code Section                                    213243 non-null  object \n",
    "Charge #1: Code Description                                213243 non-null  object \n",
    "Charge #1: Infraction Amount                               213243 non-null  object \n",
    "Charge #2: Code                                            213243 non-null  object \n",
    "Charge #2: Code Section                                    213243 non-null  object \n",
    "Charge #2: Code Description                                213243 non-null  object \n",
    "Charge #2: Infraction Amount                               213243 non-null  object \n",
    "Charge #3: Code                                            213243 non-null  object \n",
    "Charge #3: Code Section                                    213243 non-null  object \n",
    "Charge #3: Code Description                                213243 non-null  object \n",
    "Charge #3: Infraction Amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Charge #1: Code Description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the respondents, some are individuals and some are commerical entities as indicated on some rows as \"LLC.\" Therefore, need to create a separate column labeling whether the respondent is a person or otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 1000000000)\n",
    "merged_train_df[\"Respondent First Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_first_name = [\"INC\", \"CORP\", \"MANAGEMENT\",\"BUS SERVICE AND TOUR\", \n",
    "\"SCIENCES DIVISION\",\n",
    "\"HOUSING DEVELOPMENT\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_last_name = [\"INC\", \"CORP\", \"MANAGEMENT\",\"FIRST HOME PROPERTIES\",\n",
    "\"COR\",\n",
    "\"3 NYC\",\n",
    "\"HPENY HOUSING DEVELOPMENT FUND\",\n",
    "\"RT HUDSON ELEMENTARY SCHOOL\",\n",
    "\"DEVELOPMENT CO\",\n",
    "\"HOLDING CO\",\n",
    "\"BANANA KELLY HSG DEVE\",\n",
    "\"AQUA PROPERTIES\",\n",
    "\"THE BROOKLYN UNION GAS CO\",\n",
    "\"VANDERBILT MORTGAGE AND FINANC\",\n",
    "\"AMERICAN BROKERS CONDUIT\",\n",
    "\"CMI BUSINESS FURNITURE\",\n",
    "\"FRIENDS LAND DEVELOP\",\n",
    "\"HARBOR VIEW PROP LTD\",\n",
    "\"INGERSOLL TENANT ASSOC\",\n",
    "\"THE BROOKLYN UNION GAS COMPANY \",\n",
    "\"PLAZA CONSTRUCTION\",\n",
    "\"AUTO AUCTION\"\n",
    "\"FIRST HOME PROP\",\n",
    "\"1046 WASHINGTON AVE HDFC\",\n",
    "\"DIEGO BEEKMAN MUTUAL HOUSING A\",\n",
    "\"REV MANAGEMENT\",\n",
    "\"LANDSLIDE PROPERTIES\",\n",
    "\"NEIGHBORHOOD RESTORE HOUSING D\",\n",
    "\"HTB ENTERPRISES LTD\",\n",
    "\"ALLIANCE OF INDIVIDUA\",\n",
    "\"WJR PROPERTIES INC\",\n",
    "\"WJR PROPERTIES INC\",\n",
    "\"KEYSPAN ENERGY DELIVERY NYC\",\n",
    "\"RLTY\",\n",
    "\"FIRST UNITED MORTGAGE BANKING\",\n",
    "\"ASSET PLUSS MANAGEMENT SERVICE\",\n",
    "\"KEYSPAN ENERGY DELIVERY N Y C\",\n",
    "\"WELLS FARGO HOME MORT\",\n",
    "\"ALLIANCE OF INDIVIDUAL\",\n",
    "\"NEIGHBORHOOD RESTORE HDFC\",\n",
    "\"WILMINGTON SAVINGS FUND SOCIET\",\n",
    "\"YOUNG ISRAEL OF AVENUE K\",\n",
    "\"FREMONT INVESTMENT LOAN\",\n",
    "\"BELL ATLANTIC\",\n",
    "\"EM ESS PETROLEUM CORP\",\n",
    "\"PI CONSTRUCTION SERVICE INC\",\n",
    "\"US BANK NATIONAL ASSOCIATION\",\n",
    "\"CONKLIN MGMT CO\",\n",
    "\"CON EDISON\",\n",
    "\"CONSOLIDATED EDISON\",\n",
    "\"EMPIRE CITY SUBWAY\",\n",
    "\"DEUTSCHE BANK NATIONAL TRUST C\",\n",
    "\"NATIONAL GRID\",\n",
    "\"CONTACT HOLDINGS CORP\",\n",
    "\"U S BANK NATIONAL ASSOCIATION\",\n",
    "\"G G ASSOCIATES\",\n",
    "\"WELLS FARGO BANK\",\n",
    "\"LUCKY SEAFOOD\",\n",
    "\"AGENT OWNER\",\n",
    "\"FEDERAL NATIONAL MORTGAGE ASSO\",\n",
    "\"AMENCAN HOME MORTGAGE\",\n",
    "\"HOMESIDE LENDING\",\n",
    "\"HSBC BANK USA\",\n",
    "\"HSBC BANK USA NA\",\n",
    "\"HIGH STATE RLTY CORP\",\n",
    "\"NYC HOUSING AUTHORITY\",\n",
    "\"PLAZA CONSTRUCTION CORP\",\n",
    "\"EASY STREET PLUMBING INC\",\n",
    "\"1249 WEBSTER AVE RLTY\",\n",
    "\"DEVELOP\", \"BANK\", \"RESOURCES\", \"SERVICES\", \"LLC\", \"SCHOOL\", \"HOME\",\"NATIONAL GRID\",\"SAM CONEY ISLAND LLC\"\n",
    "                    \"ALL PHASE PLUMBING CORP\",\"ERCAT REALTY CORP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df['Respondent Last Name'] = merged_train_df['Respondent Last Name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_checker(sentence):\n",
    "#     if any(word in key_words_last_name for word in sentence.lower().split()):\n",
    "#         return 'Not Person'\n",
    "#     else:\n",
    "#         return 'Person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['Respondent Status'] = merged_df['Respondent Last Name'].apply(word_checker)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(my_string):\n",
    "    for word in key_words_last_name:\n",
    "        for x in merged_df[\"Respondent Last Name\"]:\n",
    "            if word.lower() in my_string.lower():\n",
    "                return \"Not Person\"\n",
    "            else:\n",
    "                return \"Person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df[\"Respondent Status\"]= merged_train_df[\"Respondent Last Name\"].apply(get_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Respondent Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[merged_df['Respondent Last Name'] == \"NATIONAL GRID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(\"JURISDICTION NAME\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth = 1000000\n",
    "# pd.set_option('display.max_columns', 2000000000)\n",
    "# pd.set_option('display.max_rows', 1000000000)\n",
    "# pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSM\n",
    "\n",
    "just pulled in one feature b/c i need to do more work on the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_model.fit(df[\"Violation Location (City)\"], df[\"Hearing Result\"])\n",
    "y_hat = dummy_model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(df[\"Hearing Result\"],y_hat)\n",
    "macro_precision_score=precision_score(df[\"Hearing Result\"], y_hat, average='macro')\n",
    "micro_precision_score=precision_score(df[\"Hearing Result\"] , y_hat, average='micro')\n",
    "macro_recall_score=recall_score(df[\"Hearing Result\"], y_hat, average='macro')\n",
    "micro_recall_score=recall_score(df[\"Hearing Result\"], y_hat, average='micro')\n",
    "\n",
    "print('Accuracy Score: {}'.format(acc))\n",
    "print('Macro Precision Score: {}'.format(macro_precision_score))\n",
    "print('Micro Precision Score: {}'.format(micro_precision_score))\n",
    "print('Macro Recall Score: {}'.format(macro_recall_score))\n",
    "print('Micro Recall Score: {}'.format(micro_recall_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
